# 2.7 训练和评估
我们在完成了模型的训练后，需要在测试集/验证集上完成模型的验证，以确保我们的模型**具有泛化能力、不会出现过拟合等问题**。在PyTorch中，训练和评估的流程是一致的，只是在训练过程中需要将模型的参数进行更新，而在评估过程中则不需要更新参数。

经过本节的学习，你将收获：

- PyTorch的训练/评估模式的开启
- 完整的训练/评估流程

### 2.7.1 开启训练/评估模式
完成了上述设定后就可以加载数据开始训练模型了。首先应该设置模型的状态：如果是训练状态，那么模型的参数应该支持反向传播的修改；如果是验证/测试状态，则不应该修改模型参数。在PyTorch中，模型的状态设置非常简便，如下的两个操作二选一即可：

```python
model.train()   # 训练状态
model.eval()   # 验证/测试状态
```

### 2.7.2 完整的训练和评估流程
#### 1. 训练流程
我们前面在DataLoader构建完成后介绍了如何从中读取数据，在训练过程中使用类似的操作即可，区别在于此时要用for循环读取DataLoader中的全部数据。

```python
for data, label in train_loader:
```

之后将数据放到GPU上用于后续计算，此处以.cuda()为例

```python
data, label = data.cuda(), label.cuda()
```

开始用当前批次数据做训练时，应当先将优化器的梯度置零：

```python
optimizer.zero_grad()
```

之后将data送入模型中训练：

```python
output = model(data)
```

根据预先定义的criterion计算损失函数：

```python
loss = criterion(output, label)
```

将loss反向传播回网络：

```python
loss.backward()
```

使用优化器更新模型参数：

```python
optimizer.step()
```

这样一个训练过程就完成了，后续还可以计算模型准确率等指标，这部分会在下一节的图像分类实战中加以介绍。

#### 2. 测试/验证流程
验证/测试的流程基本与训练过程一致，不同点在于：

- 需要预先设置torch.no_grad，以及将model调至eval模式
- 不需要将优化器的梯度置零
- 不需要将loss反向回传到网络
- 不需要更新optimizer

一个完整的图像分类的训练过程如下所示：

```python
def train(epoch):
    model.train()
    train_loss = 0
    for data, label in train_loader:
        data, label = data.cuda(), label.cuda()
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, label)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()*data.size(0)
    train_loss = train_loss/len(train_loader.dataset)
		print('Epoch: {} \tTraining Loss: {:.6f}'.format(epoch, train_loss))

```

对应的，一个完整图像分类的验证过程如下所示：

```python
def val(epoch):       
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for data, label in val_loader:
            data, label = data.cuda(), label.cuda()
            output = model(data)
            preds = torch.argmax(output, 1)
            loss = criterion(output, label)
            val_loss += loss.item()*data.size(0)
            running_accu += torch.sum(preds == label.data)
    val_loss = val_loss/len(val_loader.dataset)
    print('Epoch: {} \tTraining Loss: {:.6f}'.format(epoch, val_loss))
```
对于图像分类任务，我们还可以使用sklearn.metrics中的classification_report函数来计算模型的准确率、召回率、F1值等指标，如下所示：

```python
from sklearn.metrics import classification_report
"""
将下方代码的labels和preds替换为模型预测出来的所有label和preds，
target_names替换为类别名称，
既可得到模型的分类报告
"""
print(classification_report(labels.cpu(), preds.cpu(), target_names=class_names))
```
除此之外，我们还可以使用`torcheval`或`torchmetric`来对模型进行评估。

### 2.7.3 CUDA的使用
在训练和测试的过程中，由于运算量巨大、任务繁重，因此良好的算力是深度学习的重要保障。GPU的出现，让计算机的算力得到了极大的提高，因此我们利用PyTorch编写完模型之后，可以让多个GPU来参与训练，减少训练时间。你可以在命令行使用`nvidia-smi`命令来查看你的GPU信息和使用情况。

CUDA是NVIDIA提供的一种GPU并行计算框架。对于GPU本身的编程，使用的是CUDA语言来实现的。但是，在我们使用PyTorch编写深度学习代码时，使用的CUDA又是另一个意思。在PyTorch使用 CUDA表示要开始要求我们的模型或者数据开始使用GPU了。

在编写程序中，当我们使用了`.cuda()`  时，其功能是让我们的模型或者数据从CPU迁移到GPU上（默认是0号GPU）当中，通过GPU开始计算。

注：
1. 我们使用GPU时使用的是.cuda()而不是使用.gpu()。这是因为当前GPU的编程接口采用CUDA，但是市面上的GPU并不是都支持CUDA，只有部分NVIDIA的GPU才支持，AMD的GPU编程接口采用的是OpenCL，在现阶段PyTorch并不支持。

2. 数据在GPU和CPU之间进行传递时会比较耗时，我们应当尽量避免数据的切换。

3. GPU运算很快，但是在使用简单的操作时，我们应该尽量使用CPU去完成。

4. 当我们的服务器上有多个GPU，我们应该指明我们使用的GPU是哪一块，如果我们不设置的话，`tensor.cuda()`方法会默认将tensor保存到第一块GPU上，等价于`tensor.cuda(0)`，这将有可能导致爆出`out of memory`的错误,我们可以通过以下两种方式继续设置。

```py
 #设置在文件最开始部分
import os
os.environ["CUDA_VISIBLE_DEVICE"] = "2" # 设置默认的显卡
```

```py
 CUDA_VISBLE_DEVICE=0,1 python train.py # 使用0，1两块GPU
```

### 2.7.4 PipeLine
pytorch整体的数据pipeline设计的比较简单，是典型的生产者消费者的模式,总共分为Sampler，Dataset，DataloaderIter以及Dataloader这四个抽象层次。Sampler负责生成读取的index序列，Dataset负责根据index读取相应数据并执行预处理，DataloaderIter负责协调多进程执行Dataset，而Dataloader则是最顶层的抽象。详见[Pytorch数据Pipeline设计总结](https://zhuanlan.zhihu.com/p/351666693)。

1. 单进程数据读取
```py
class _SingleProcessDataLoaderIter(_BaseDataLoaderIter):
    def __init__(self, loader):
        super(_SingleProcessDataLoaderIter, self).__init__(loader)
        assert self._timeout == 0  # 确保超时时间为0，即没有超时限制
        assert self._num_workers == 0  # 确保工作进程数为0，即没有使用多进程

        self._dataset_fetcher = _DatasetKind.create_fetcher(
            self._dataset_kind, self._dataset, self._auto_collation, self._collate_fn, self._drop_last)

    def _next_data(self):
        index = self._next_index()  # 获取下一个索引位置（可能会引发StopIteration异常）
        data = self._dataset_fetcher.fetch(index)  # 获取下一个数据（可能会引发StopIteration异常）
        if self._pin_memory:
            data = _utils.pin_memory.pin_memory(data)  # 将数据存储到固定的内存中以加速传输
        return data
```

1. 多进程数据读取 
多进程数据获取核心模型就是生产者-消费者模型。由于pytorch是采用纯python实现的DataLoaderIter，没法绕开python的GIL，所以采用了多进程进行数据获取。详细的生产者消费者的模型示意图如下。核心的角色有Dataset进程，预处理队列。进程间采用进程间队列来通信，线程与主线程之间采用线程队列来通信。核心的队列有指定获取数据的index队列，Dataset进程向主进程返回结果的结果队列，以及线程对结果队列中的数据做预处理的线程队列。

## 参考资料
1. [并行计算简介](https://github.com/datawhalechina/thorough-pytorch/blob/main/docs/%E7%AC%AC%E4%BA%8C%E7%AB%A0/2.3%20%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E7%AE%80%E4%BB%8B.html)
2. [Pytorch数据Pipeline设计总结](https://zhuanlan.zhihu.com/p/351666693)
3. chatGPT